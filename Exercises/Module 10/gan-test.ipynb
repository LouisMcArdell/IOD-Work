{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# A module to transform data to NumPy arrays and create random noise\nimport numpy as np \nfrom tensorflow.keras.models import Sequential\n# Layers to be used in generator and discriminator\nfrom tensorflow.keras.layers import Dense, LeakyReLU \n# A module to plot generated data \nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:21:16.546838Z","iopub.execute_input":"2023-12-28T10:21:16.547290Z","iopub.status.idle":"2023-12-28T10:21:32.782382Z","shell.execute_reply.started":"2023-12-28T10:21:16.547251Z","shell.execute_reply":"2023-12-28T10:21:32.781143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create variable X\nX_train = np.linspace(-1, 1, 1000)\n# Reshape X variable\nX_train = X_train.reshape(-1, 1)\n# Create variable Y such that y = x\ny_train = X_train","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:21:32.784596Z","iopub.execute_input":"2023-12-28T10:21:32.785384Z","iopub.status.idle":"2023-12-28T10:21:32.792076Z","shell.execute_reply.started":"2023-12-28T10:21:32.785336Z","shell.execute_reply":"2023-12-28T10:21:32.790628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_generator(noise_dim):\n  # Add layers one after one in the sequence\n  model = Sequential() \n  # First fully connected layer\n  model.add(Dense(16, activation = 'relu', kernel_initializer = 'he_uniform', input_dim = noise_dim))\n  # Add LeakyReLU activation function\n  model.add(LeakyReLU(alpha=0.01))\n  # Output layer with the shape of 2\n  model.add(Dense(2, activation = 'linear'))\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:21:39.375727Z","iopub.execute_input":"2023-12-28T10:21:39.376150Z","iopub.status.idle":"2023-12-28T10:21:39.383045Z","shell.execute_reply.started":"2023-12-28T10:21:39.376118Z","shell.execute_reply":"2023-12-28T10:21:39.381613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator():\n  # Add layers one after one in the sequence\n  model = Sequential() \n  # First fully connected layer\n  model.add(Dense(32, activation = 'relu', kernel_initializer = 'he_uniform', input_dim = 2))\n  # Add LeakyReLU activation function\n  model.add(LeakyReLU(alpha=0.01))\n  # Second fully connected layer\n  model.add(Dense(8, activation = 'relu', kernel_initializer = 'he_uniform'))\n  # Add LeakyReLU activation function\n  model.add(LeakyReLU(alpha=0.01))\n  # Output layer with the shape of 2\n  model.add(Dense(1, activation = 'sigmoid'))\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:21:57.045461Z","iopub.execute_input":"2023-12-28T10:21:57.045894Z","iopub.status.idle":"2023-12-28T10:21:57.053633Z","shell.execute_reply.started":"2023-12-28T10:21:57.045857Z","shell.execute_reply":"2023-12-28T10:21:57.052382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def construct_models(noise_dim):\n      # Build the discriminator model\n      discriminator = build_discriminator() \n      # Compile the discriminator\n      discriminator.compile(loss = 'binary_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])\n      # Build the generator model\n      generator = build_generator(noise_dim) \n      # Freeze the discriminator during generator training\n      discriminator.trainable = False\n      gan = Sequential() \n      # Pit the generator and discriminator against each other\n      gan.add(generator)\n      gan.add(discriminator)\n      # Compile the GAN model\n      gan.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n      return generator, discriminator, gan","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:22:10.409351Z","iopub.execute_input":"2023-12-28T10:22:10.409795Z","iopub.status.idle":"2023-12-28T10:22:10.417424Z","shell.execute_reply.started":"2023-12-28T10:22:10.409757Z","shell.execute_reply":"2023-12-28T10:22:10.416391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define discriminator loss function\ndef disc_loss(model, X, y):\n\t      # Train the model on a batch of data and return loss value\n\t      return model.train_on_batch(X,y)\n# Define generator loss function\ndef gen_loss(model, X, y):\n\t      # Train the model on a batch of data and return loss value\n\t      return model.train_on_batch(X,y)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:22:22.814178Z","iopub.execute_input":"2023-12-28T10:22:22.814622Z","iopub.status.idle":"2023-12-28T10:22:22.822509Z","shell.execute_reply.started":"2023-12-28T10:22:22.814589Z","shell.execute_reply":"2023-12-28T10:22:22.820841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef print_generated_samples(batch_size, noise_dim):\n      # Create test data\n      X_test = np.random.uniform(low=-1, high =1, size=(batch_size//2, 1))\n      y_test = X_test\n      # Generate samples\n      noise = np.random.normal(0, 1, (batch_size//2, noise_dim))\n      gen_data = generator.predict(noise)  \n      # Plot generated data\n      plt.scatter(X_test, y_test, color = 'red')\n      plt.scatter(gen_data[:,0], gen_data[:,1], color =  'blue')\n      plt.xlim(-1,1)\n      plt.ylim(-1,1)\n      plt.legend([\"real data\", \"generated data\"], loc = \"lower right\")\n      plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:22:37.995245Z","iopub.execute_input":"2023-12-28T10:22:37.995670Z","iopub.status.idle":"2023-12-28T10:22:38.004866Z","shell.execute_reply.started":"2023-12-28T10:22:37.995637Z","shell.execute_reply":"2023-12-28T10:22:38.003520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(generator, discriminator, gan, noise_dim, epochs, batch_size):\n  # Enumerate over epochs\n  for e in range(epochs):\n          # Random normal array for generator input \n          noise = np.random.normal(0, 1, (batch_size, noise_dim))\n          # Create fake images by the generator\n          fake_samples = generator.predict(noise)\n          # Stack X and Y variable horizontally to build the dataset\n          real_data = np.hstack((X_train, y_train))\n          # Get a random real data points from the training data\n          real_data = real_data[np.random.randint(0, real_data.shape[0], size = batch_size)]\n          # Create real labels\n          real_labels = np.ones((batch_size, 1))*0.9\n          # Generate fake labels generated data points as zeros\n          fake_labels = np.zeros((batch_size, 1))\n          # Calculate the loss of real data points\n          discriminator_loss_real = disc_loss(discriminator, real_data, real_labels)\n          # Calculate the loss of generated data points\n          discriminator_loss_fake = disc_loss(discriminator, fake_samples, fake_labels)\n          # Compute total discriminator loss\n          discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n          # Generate random points as input for the generator\n          x_gan = np.random.normal(0, 1, (batch_size, noise_dim))\n          # generate real labels for gan\n          y_gan = np.ones((batch_size, 1))\n          #calculate the generator loss\n          gan_loss = gen_loss(gan, x_gan, y_gan)\n          # Print the progress\n          if e % 10 == 0 or e == epochs-1:\n            print('Epoch: ', e, ' Generator Loss: ', gan_loss , ' Discriminator Loss: ', discriminator_loss)\n            print_generated_samples(batch_size, noise_dim)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:22:57.822187Z","iopub.execute_input":"2023-12-28T10:22:57.822657Z","iopub.status.idle":"2023-12-28T10:22:57.835594Z","shell.execute_reply.started":"2023-12-28T10:22:57.822618Z","shell.execute_reply":"2023-12-28T10:22:57.834278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the models \ngenerator, discriminator, gan = construct_models(100) \n# Train GAN \ntraining(generator, discriminator, gan, 100, 10000, 128)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T10:23:14.340764Z","iopub.execute_input":"2023-12-28T10:23:14.342063Z","iopub.status.idle":"2023-12-28T10:48:59.772732Z","shell.execute_reply.started":"2023-12-28T10:23:14.342010Z","shell.execute_reply":"2023-12-28T10:48:59.771632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}